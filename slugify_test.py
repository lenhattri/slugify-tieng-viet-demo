# test_slugify.py
import re
import unicodedata as ud
import pytest
from slugify import slugify_tieng_viet

# ======================
# 1) CORE SLUG BEHAVIOR
# ======================

# 30 ca input -> expected slug (suffix_mode máº·c Ä‘á»‹nh = none)
@pytest.mark.parametrize("src, expected", [
    ("TÃ´i Tháº¥y Hoa VÃ ng TrÃªn Cá» Xanh", "toi-thay-hoa-vang-tren-co-xanh"),
    ("  A---B__C   ", "a-b-c"),
    ("Xin chÃ o ğŸŒŸğŸ”¥", "xin-chao"),
    ("CafÃ© Ãœbermensch", "cafe-ubermensch"),
    ("", ""),
    ("ğŸ”¥ğŸ”¥", ""),
    ("Ä‘i-cho-nhanh", "di-cho-nhanh"),
    ("TÃ´Ìi Æ°Æ¡m mÆ¡", "toi-uom-mo"),                 # trá»™n NFD/NFC
    ("Helloâ€”world", "hello-world"),                # em dash
    ("A___B...C", "a-b-c"),
    ("KÃ½_tá»± Ä‘áº·c biá»‡t!!!", "ky-tu-dac-biet"),
    ("ÄÆ°á»ng Ä‘ua F1 2025", "duong-dua-f1-2025"),
    ("NÄƒm 2020: Ä‘iá»u gÃ¬?", "nam-2020-dieu-gi"),
    ("   ---   ", ""),
    ("Cá» VN ğŸ‡»ğŸ‡³", "co-vn"),
    ("naÃ¯ve faÃ§ade rÃ´le", "naive-facade-role"),
    ("ÅÃ³dÅº", "odz"),                               # Å bá»‹ loáº¡i, cÃ²n "odz"
    ("ä¸­æ–‡ ç©ºæ ¼", ""),                               # non-ASCII bá»‹ bá» háº¿t
    ("Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ñ‚ĞµĞºÑÑ‚", ""),                         # non-ASCII bá»‹ bá» háº¿t
    ("email@example.com", "email-example-com"),
    ("path/to/file", "path-to-file"),
    ("100% há»£p lá»‡", "100-hop-le"),
    ("C++ vs C#", "c-vs-c"),
    ("   abc", "abc"),
    ("abc   ", "abc"),
    ("--abc--", "abc"),
    ("aâ€”bâ€”câ€”d", "a-b-c-d"),
    ("a\tb\nc", "a-b-c"),
    ("SÃ i GÃ²n â€“ HÃ  Ná»™i", "sai-gon-ha-noi"),        # en dash
    ("Äáº¶C Sáº¢N", "dac-san"),
])
def test_slug_outputs(src, expected):
    assert slugify_tieng_viet(src) == expected


# CÃ¡c quy táº¯c báº¥t biáº¿n: chá»‰ [a-z0-9-], khÃ´ng '--', khÃ´ng '-' Ä‘áº§u/cuá»‘i
@pytest.mark.parametrize("src", [
    "TÃ´i Tháº¥y Hoa VÃ ng TrÃªn Cá» Xanh",
    "  A---B__C   ",
    "Xin chÃ o ğŸŒŸğŸ”¥",
    "CafÃ© Ãœbermensch",
    "",
    "ğŸ”¥ğŸ”¥",
    "Ä‘i-cho-nhanh",
    "TÃ´Ìi Æ°Æ¡m mÆ¡",
    "Helloâ€”world",
    "A___B...C",
])
def test_charset_and_hyphen_rules(src):
    out = slugify_tieng_viet(src)
    assert "--" not in out
    assert out == out.strip("-")
    assert all(c.islower() or c.isdigit() or c == "-" for c in out)


# NFD/NFC pháº£i cho cÃ¹ng káº¿t quáº£
def test_nfd_nfc_equivalence():
    s = "TÃ´Ìi Æ°Æ¡m mÆ¡"  # 'Ã´Ì' á»Ÿ NFD (Ã´ + dáº¥u) + NFC trá»™n
    nfd = ud.normalize("NFD", s)
    nfc = ud.normalize("NFC", s)
    assert slugify_tieng_viet(nfd) == slugify_tieng_viet(nfc)


# Idempotence: slugify(slug) == slug
@pytest.mark.parametrize("src", [
    "TÃ´i Tháº¥y Hoa VÃ ng TrÃªn Cá» Xanh!!!",
    "  A---B__C   ",
    "Xin chÃ o ğŸŒŸğŸ”¥",
    "Ä‘i-cho-nhanh",
])
def test_idempotent(src):
    once = slugify_tieng_viet(src)
    twice = slugify_tieng_viet(once)
    assert once == twice


# max_len: cáº¯t â€œthÃ´ng minhâ€, khÃ´ng Ä‘á»ƒ '-' á»Ÿ cuá»‘i
@pytest.mark.parametrize("src,max_len,acceptable", [
    ("di-cho-nhanh", 5, {"di-cho", "di"}),      # Æ°u tiÃªn cáº¯t táº¡i '-'
    ("abcde", 3, {"abc"}),                      # khÃ´ng cÃ³ '-', cáº¯t cá»©ng
    ("a-b-c", 1, {"a"}),                        # ráº¥t ngáº¯n
    ("a-b-c", 2, {"a", "a-b"}),                 # cÃ³ thá»ƒ cáº¯t táº¡i '-'
    ("---", 2, {""}),                           # toÃ n separator â†’ rá»—ng
    ("hello-world", 11, {"hello-world"}),       # vá»«a khÃ­t
    ("hello-world", 10, {"hello"}),             # cáº¯t táº¡i '-'
])
def test_max_len_behavior(src, max_len, acceptable):
    out = slugify_tieng_viet(src, max_len=max_len)
    assert out in acceptable
    assert not out.endswith("-")


# ======================
# 2) SUFFIX MODE TESTS
# ======================

def test_suffix_none_default_same_as_base():
    base = slugify_tieng_viet("Mot bai viet")  # none by default
    explicit = slugify_tieng_viet("Mot bai viet", suffix_mode="none")
    assert base == explicit


def test_suffix_random4_pattern():
    out = slugify_tieng_viet("Má»™t bÃ i viáº¿t", suffix_mode="random4")
    assert re.fullmatch(r"[a-z0-9-]+-[0-9a-f]{4}", out)
    assert "--" not in out and out == out.strip("-")


def test_suffix_random6_pattern():
    out = slugify_tieng_viet("Má»™t bÃ i viáº¿t", suffix_mode="random6")
    assert re.fullmatch(r"[a-z0-9-]+-[0-9a-f]{6}", out)
    assert "--" not in out and out == out.strip("-")


def test_suffix_date_pattern():
    out = slugify_tieng_viet("abc", suffix_mode="date")
    # yyyyMMdd á»Ÿ cuá»‘i
    assert re.fullmatch(r"abc-\d{8}", out)


def test_suffix_datetime_pattern():
    out = slugify_tieng_viet("abc", suffix_mode="datetime")
    # yyyyMMddHHmm á»Ÿ cuá»‘i
    assert re.fullmatch(r"abc-\d{12}", out)


def test_suffix_respects_max_len_boundary():
    # "abcde" + "-" + 4 hex = 10
    out = slugify_tieng_viet("abcde", suffix_mode="random4", max_len=10)
    assert re.fullmatch(r"abcde-[0-9a-f]{4}", out)

    # max_len 9: cáº¯t táº¡i '-', chá»‰ cÃ²n base
    out2 = slugify_tieng_viet("abcde", suffix_mode="random4", max_len=9)
    assert out2 == "abcde"


def test_suffix_cut_on_hyphen_of_base():
    # base = "hello-world" (11 kÃ½ tá»±). ThÃªm -XXXXXX sáº½ vÆ°á»£t nÃªn cáº¯t trÆ°á»›c dáº¥u '-'
    out = slugify_tieng_viet("hello-world", suffix_mode="random6", max_len=11)
    assert out == "hello-world"


@pytest.mark.parametrize("mode", ["none", "random4", "random6", "date", "datetime"])
def test_suffix_modes_invariants(mode):
    out = slugify_tieng_viet("TiÃªu Ä‘á»: thá»­ nghiá»‡m suffix!", suffix_mode=mode, max_len=80)
    assert "--" not in out
    assert out == out.strip("-")
    assert all(c.islower() or c.isdigit() or c == "-" for c in out)


def test_suffix_empty_input_returns_empty():
    assert slugify_tieng_viet("", suffix_mode="random6") == ""
    assert slugify_tieng_viet("ğŸ”¥ğŸ”¥", suffix_mode="date") == ""


def test_suffix_emoji_only_is_empty_even_with_suffix():
    assert slugify_tieng_viet("ğŸ¤¯ğŸ¤¯", suffix_mode="random4") == ""
