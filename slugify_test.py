# test_slugify.py
import unicodedata as ud
import pytest
from slugify import slugify_tieng_viet

# 30 ca input -> expected slug
@pytest.mark.parametrize("src, expected", [
    ("TÃ´i Tháº¥y Hoa VÃ ng TrÃªn Cá» Xanh", "toi-thay-hoa-vang-tren-co-xanh"),
    ("  A---B__C   ", "a-b-c"),
    ("Xin chÃ o ğŸŒŸğŸ”¥", "xin-chao"),
    ("CafÃ© Ãœbermensch", "cafe-ubermensch"),
    ("", ""),
    ("ğŸ”¥ğŸ”¥", ""),
    ("Ä‘i-cho-nhanh", "di-cho-nhanh"),
    ("TÃ´Ìi Æ°Æ¡m mÆ¡", "toi-uom-mo"),                 # trá»™n NFD/NFC
    ("Helloâ€”world", "hello-world"),                # em dash
    ("A___B...C", "a-b-c"),
    ("KÃ½_tá»± Ä‘áº·c biá»‡t!!!", "ky-tu-dac-biet"),
    ("ÄÆ°á»ng Ä‘ua F1 2025", "duong-dua-f1-2025"),
    ("NÄƒm 2020: Ä‘iá»u gÃ¬?", "nam-2020-dieu-gi"),
    ("   ---   ", ""),
    ("Cá» VN ğŸ‡»ğŸ‡³", "co-vn"),
    ("naÃ¯ve faÃ§ade rÃ´le", "naive-facade-role"),
    ("ÅÃ³dÅº", "odz"),                               # Å bá»‹ loáº¡i, cÃ²n "odz"
    ("ä¸­æ–‡ ç©ºæ ¼", ""),                               # non-ASCII bá»‹ bá» háº¿t
    ("Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ñ‚ĞµĞºÑÑ‚", ""),                         # non-ASCII bá»‹ bá» háº¿t
    ("email@example.com", "email-example-com"),
    ("path/to/file", "path-to-file"),
    ("100% há»£p lá»‡", "100-hop-le"),
    ("C++ vs C#", "c-vs-c"),
    ("   abc", "abc"),
    ("abc   ", "abc"),
    ("--abc--", "abc"),
    ("aâ€”bâ€”câ€”d", "a-b-c-d"),
    ("a\tb\nc", "a-b-c"),
    ("SÃ i GÃ²n â€“ HÃ  Ná»™i", "sai-gon-ha-noi"),        # en dash
    ("Äáº¶C Sáº¢N", "dac-san"),
])
def test_slug_outputs(src, expected):
    assert slugify_tieng_viet(src) == expected


# CÃ¡c quy táº¯c báº¥t biáº¿n: chá»‰ [a-z0-9-], khÃ´ng '--', khÃ´ng '-' Ä‘áº§u/cuá»‘i
@pytest.mark.parametrize("src", [
    "TÃ´i Tháº¥y Hoa VÃ ng TrÃªn Cá» Xanh",
    "  A---B__C   ",
    "Xin chÃ o ğŸŒŸğŸ”¥",
    "CafÃ© Ãœbermensch",
    "",
    "ğŸ”¥ğŸ”¥",
    "Ä‘i-cho-nhanh",
    "TÃ´Ìi Æ°Æ¡m mÆ¡",
    "Helloâ€”world",
    "A___B...C",
])
def test_charset_and_hyphen_rules(src):
    out = slugify_tieng_viet(src)
    assert "--" not in out
    assert out == out.strip("-")
    assert all(c.islower() or c.isdigit() or c == "-" for c in out)


# NFD/NFC pháº£i cho cÃ¹ng káº¿t quáº£
def test_nfd_nfc_equivalence():
    s = "TÃ´Ìi Æ°Æ¡m mÆ¡"  # 'Ã´Ì' á»Ÿ NFD (Ã´ + dáº¥u) + NFC trá»™n
    nfd = ud.normalize("NFD", s)
    nfc = ud.normalize("NFC", s)
    assert slugify_tieng_viet(nfd) == slugify_tieng_viet(nfc)


# Idempotence: slugify(slug) == slug
@pytest.mark.parametrize("src", [
    "TÃ´i Tháº¥y Hoa VÃ ng TrÃªn Cá» Xanh!!!",
    "  A---B__C   ",
    "Xin chÃ o ğŸŒŸğŸ”¥",
    "Ä‘i-cho-nhanh",
])
def test_idempotent(src):
    once = slugify_tieng_viet(src)
    twice = slugify_tieng_viet(once)
    assert once == twice


# max_len: cáº¯t â€œthÃ´ng minhâ€, khÃ´ng Ä‘á»ƒ '-' á»Ÿ cuá»‘i
@pytest.mark.parametrize("src,max_len,acceptable", [
    ("di-cho-nhanh", 5, {"di-cho", "di"}),      # Æ°u tiÃªn cáº¯t táº¡i '-'
    ("abcde", 3, {"abc"}),                      # khÃ´ng cÃ³ '-', cáº¯t cá»©ng
    ("a-b-c", 1, {"a"}),                        # ráº¥t ngáº¯n
    ("a-b-c", 2, {"a", "a-b"}),                 # cÃ³ thá»ƒ cáº¯t táº¡i '-'
    ("---", 2, {""}),                           # toÃ n separator â†’ rá»—ng
    ("hello-world", 11, {"hello-world"}),       # vá»«a khÃ­t
    ("hello-world", 10, {"hello"}),             # cáº¯t táº¡i '-'
])
def test_max_len_behavior(src, max_len, acceptable):
    out = slugify_tieng_viet(src, max_len=max_len)
    assert out in acceptable
    assert not out.endswith("-")
